{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50e2497b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m     cv2.putText(img,\u001b[33m'\u001b[39m\u001b[33meye\u001b[39m\u001b[33m'\u001b[39m,(x+ex+\u001b[32m10\u001b[39m,y+ey+\u001b[32m10\u001b[39m),cv2.FONT_HERSHEY_SIMPLEX,\u001b[32m0.5\u001b[39m,(\u001b[32m0\u001b[39m,\u001b[32m255\u001b[39m,\u001b[32m0\u001b[39m),\u001b[32m2\u001b[39m)\n\u001b[32m     17\u001b[39m cv2.imshow(\u001b[33m'\u001b[39m\u001b[33mimg\u001b[39m\u001b[33m'\u001b[39m, img)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43mcv2\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03mCon respecto a los parametros de la función detectMultiScale, dado que de esto puede depender mucho el resultado de la detección, se explican a continuación:\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m┌────────────────────────────────────────────────────────────────────┐\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     79\u001b[39m \n\u001b[32m     80\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('content/pexels-cottonbro.jpg')\n",
    "faseClassifier = cv2.CascadeClassifier('content/haarcascade_frontalface_default.xml')#el archivo xml tiene el modelo ya entrenado\n",
    "eyeClassifier = cv2.CascadeClassifier('content/haarcascade_eye.xml')\n",
    "imgGrey = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = faseClassifier.detectMultiScale(imgGrey, scaleFactor=1.3, minNeighbors=5, minSize=(30,30),)\n",
    "\n",
    "for (x, y, w, h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    cv2.putText(img,'face',(x+10,y+10),cv2.FONT_HERSHEY_SIMPLEX,1,(255,0,0),2)\n",
    "    faceDectected = imgGrey[y:y+h, x:x+w]#en este punto se identifico el rostro, ahora se identifica los ojos\n",
    "    faceDectectColor = img[y:y+h, x:x+w]\n",
    "    eyes = eyeClassifier.detectMultiScale(faceDectected, scaleFactor=1.2, minNeighbors=20, minSize=(1,1),)#Ahora si se detectan los ojos\n",
    "for (ex, ey, ew, eh) in eyes:#se dibujan los rectángulos de los ojos\n",
    "    cv2.rectangle(faceDectectColor,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    cv2.putText(img,'eye',(x+ex+10,y+ey+10),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,255,0),2)\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n",
    "\"\"\"\n",
    "Con respecto a los parametros de la función detectMultiScale, dado que de esto puede depender mucho el resultado de la detección, se explican a continuación:\n",
    "┌────────────────────────────────────────────────────────────────────┐\n",
    "│        detectMultiScale() – PARÁMETROS PRINCIPALES (OpenCV)         │\n",
    "├──────────────────┬─────────────────────────────────────────────────┤\n",
    "│ PARÁMETRO        │ QUÉ HACE / PARA QUÉ SIRVE                        │\n",
    "├──────────────────┼─────────────────────────────────────────────────┤\n",
    "│ image            │ Imagen de entrada (DEBE estar en escala de       │\n",
    "│                  │ grises). El detector Haar NO trabaja con color.  │\n",
    "├──────────────────┼─────────────────────────────────────────────────┤\n",
    "│ scaleFactor      │ Factor de escalado de la ventana de detección.   │\n",
    "│                  │ Controla qué tan fino se escanea la imagen.      │\n",
    "│                  │                                                 │\n",
    "│                  │ Valores típicos:                                 │\n",
    "│                  │   • 1.05 – 1.1  → Muy preciso, más lento          │\n",
    "│                  │   • 1.2 – 1.3   → Balance (recomendado)          │\n",
    "│                  │   • > 1.3       → Rápido, menos preciso          │\n",
    "│                  │                                                 │\n",
    "│                  │ Efecto:                                          │\n",
    "│                  │   • Muy bajo → detecta más, pero falsos positivos│\n",
    "│                  │   • Muy alto → pierde ojos o rostros pequeños    │\n",
    "├──────────────────┼─────────────────────────────────────────────────┤\n",
    "│ minNeighbors     │ Número mínimo de detecciones cercanas necesarias │\n",
    "│                  │ para confirmar un objeto.                        │\n",
    "│                  │                                                 │\n",
    "│                  │ Interpretación:                                  │\n",
    "│                  │   • Pocos vecinos → detector permisivo           │\n",
    "│                  │   • Muchos vecinos → detector estricto           │\n",
    "│                  │                                                 │\n",
    "│                  │ Valores típicos:                                 │\n",
    "│                  │   • Rostros: 4 – 6                                │\n",
    "│                  │   • Ojos: 8 – 12                                  │\n",
    "│                  │                                                 │\n",
    "│                  │ Efecto:                                          │\n",
    "│                  │   • Bajo → más falsos positivos                  │\n",
    "│                  │   • Alto → puede perder detecciones reales       │\n",
    "├──────────────────┼─────────────────────────────────────────────────┤\n",
    "│ minSize          │ Tamaño mínimo (ancho, alto) que debe tener una   │\n",
    "│                  │ detección para ser aceptada.                     │\n",
    "│                  │                                                 │\n",
    "│                  │ Evita detectar objetos demasiado pequeños o      │\n",
    "│                  │ ruido.                                           │\n",
    "│                  │                                                 │\n",
    "│                  │ Valores típicos:                                 │\n",
    "│                  │   • Rostros: (30, 30) o mayor                    │\n",
    "│                  │   • Ojos: (10, 10)                                │\n",
    "│                  │                                                 │\n",
    "│                  │ Efecto:                                          │\n",
    "│                  │   • Muy grande → pierde objetos pequeños         │\n",
    "│                  │   • Muy pequeño → más falsas detecciones         │\n",
    "├──────────────────┼─────────────────────────────────────────────────┤\n",
    "│ maxSize          │ (Opcional) Tamaño máximo permitido para la       │\n",
    "│                  │ detección.                                       │\n",
    "│                  │                                                 │\n",
    "│                  │ Útil si sabes que el objeto no puede ser muy     │\n",
    "│                  │ grande en la imagen.                             │\n",
    "├──────────────────┼─────────────────────────────────────────────────┤\n",
    "│ flags            │ (Obsoleto) Antes se usaba para controlar el      │\n",
    "│                  │ método de escalado. Actualmente no se usa.       │\n",
    "└──────────────────┴─────────────────────────────────────────────────┘\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66c05f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu1)",
   "language": "python",
   "name": "tf-gpu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
